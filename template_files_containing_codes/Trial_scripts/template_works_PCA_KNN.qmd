---
title: "Project 1"
subtitle: "Precipitation dowmscaling using PCA-KNN combined approach"
jupyter: julia-1.9
date: 2023-11-03
author: "Samira Hossain (sh162)" # UNCOMMENT AND ADD YOUR NAME

number-sections: true
code-annotations: hover

kind: "Project"
Module: "2"
categories:
    - "Module 2"
    - "Project"

format:
    html: 
        toc-depth: 3
    docx: 
        toc: true
        toc-depth: 3
        fig-format: png
---


# Packages needed
```{julia}
#| output: false
using Dates
using MultivariateStats
using Plots
using NCDatasets
using StatsBase
```

# Reading the data in and checking dimensions

```{julia}
observedprecip_ds= NCDataset("data/precip_data_Houston/precip_tx.nc") #Storing predictand in observedprecip_ds

display(observedprecip_ds) #seeing how many attributes it has, check how many dimensions it has
obprecip_time=observedprecip_ds["time"][:]
obprecip_lon=observedprecip_ds["lon"][:]
obprecip_lat=observedprecip_ds["lat"][:]
obprecip=observedprecip_ds["precip"][:,:,:]
display(obprecip_lat)
display(obprecip_lon)
display(obprecip_time[1])

obprecip_lat=reverse(obprecip_lat)
obprecip=reverse(obprecip;dims=2)

heatmap(obprecip_lon,obprecip_lat,obprecip[:,:,1];xlabel="Longitude",ylabel="Latitude",title="Precip on $(obprecip_time[1]))")
```


```{julia}
start_date=Date(1990,1,1)
end_date=Date(2000,12,31)
time=Dates.Date.(obprecip_time)
display(time)
# display()
time_indices = findall(start_date .<= time .<= end_date)
display(time_indices)
obprecip_subset=obprecip[:,:,time_indices]

#display(obprecip_subset_time[1])

heatmap(obprecip_lon,obprecip_lat,obprecip_subset[:,:,1];xlabel="Longitude",ylabel="Latitude",title="Precip on first day of 1990")
# obprecip_time_subset=obprecip_time[time_indices]

# println(size(obprecip_subset))
#we only need 30 years of data, 1990 to 2020, so we can make a new variable called y_precip and store the data of 1990 to 2020 here.
#precip_y=
#we need 20 years of data to train, we keep the remaining 10 years of data as test

#Now the predictor variables
#temp_ds= NCDataset()  #we combine the 30 years of data we downloaded
#temp_lon=
#temp_lat=
#temp_time=


#dewtemp_ds=
#dewtemp_lon
#dewtemp_lat
#dewtemp_time          

#check dimensions and everything
#split to train and test


```


# Data merging
```{julia}
temp2020_ds= NCDataset("data/raw/2m_temperature_2020.nc") 
#temp1991_ds= NCDataset("data/raw/2m_temperature_1991.nc") 

```

```{julia}
function open_mfdataset(files::Vector{String}, variable_name::AbstractString)

    # Lists to store variable data, time data, and other coordinate data
    var_data_list = []
    time_data_list = []
    coords_data_dict = Dict()

    # Open the first file to get the coordinate names (excluding time and the main variable)
    ds = Dataset(files[1])
    dimnames = keys(ds.dim)
    coord_names = setdiff(collect(dimnames), [variable_name, "time"])
    close(ds)

    # Initialize lists for each coordinate in coords_data_dict
    for coord in coord_names
        coords_data_dict[coord] = []
    end

    # Open each file, extract data, and store in lists
    for file in files
        ds = Dataset(file)

        # Store variable and time data
        push!(var_data_list, ds[variable_name][:])
        push!(time_data_list, ds["time"][:])

        # Store other coordinate data
        for coord in coord_names
            push!(coords_data_dict[coord], ds[coord][:])
        end

        close(ds)
    end

    # Pair variable data with time data and sort by time
    sorted_pairs = sort(collect(zip(time_data_list, var_data_list)); by=x -> x[1])
    sorted_time_data = [pair[1] for pair in sorted_pairs]
    sorted_var_data = [pair[2] for pair in sorted_pairs]

    # Concatenate sorted data
    concatenated_data_dict = Dict(
        variable_name => vcat(sorted_var_data...), "time" => vcat(sorted_time_data...)
    )

    # Concatenate coordinate data and add to the dictionary
    for coord in coord_names
        concatenated_data_dict[coord] = vcat(coords_data_dict[coord]...)
    end

    return concatenated_data_dict
end

#Check for missing values in them
#Check spatial and temporal dimensions, if it matches with your y dimensions


#Split for test and train sets

```


# Data merge
```{julia}

using CDSAPI
using NCDatasets
using StatsBase: shuffle
base_path="data/raw"
files = ["2m_temperature_1990.nc", "2m_temperature_1991.nc", "2m_temperature_1992.nc","2m_temperature_1993.nc","2m_temperature_1994.nc","2m_temperature_1995.nc","2m_temperature_1996.nc","2m_temperature_1997.nc","2m_temperature_1998.nc","2m_temperature_1999.nc","2m_temperature_2000.nc","2m_temperature_2001.nc","2m_temperature_2002.nc","2m_temperature_2003.nc","2m_temperature_2004.nc","2m_temperature_2005.nc","2m_temperature_2006.nc","2m_temperature_2007.nc","2m_temperature_2008.nc","2m_temperature_2009.nc","2m_temperature_2010.nc","2m_temperature_2011.nc","2m_temperature_2012.nc","2m_temperature_2013.nc","2m_temperature_2014.nc","2m_temperature_2015.nc","2m_temperature_2016.nc","2m_temperature_2017.nc","2m_temperature_2018.nc","2m_temperature_2019.nc","2m_temperature_2020.nc"]
file_paths = [joinpath(base_path, file) for file in files]
data_dict = open_mfdataset(file_paths, "t2m")
#Check for missing values in them
#Check spatial and temporal dimensions, if it matches with your y dimensions


#Split for test and train sets


```
```{julia}

display(data_dict["longitude"])
```

```{julia}
# j = 0

# calender = Date.(dates[1]:Day(1):dates[end])
# for i in 1:length(dates)
# for date in calender
# if date == dates[i]
# j += 1
# println("match")
# println(j)
# end
# end
# end
```
```{julia}
start_date = Date(data_dict["time"][1])
end_date = Date(data_dict["time"][end])

println(start_date)
println(end_date)

# Calculate the number of days between the two dates
num_days = (end_date) - (start_date) 
num_days = Dates.value(num_days) + 1
num_years = (Dates.year(end_date) - Dates.year(start_date)) + 1

println("Number of days from $(Dates.year(start_date)) to $(Dates.year(end_date)): $num_days and $num_years years" )

n_lon = Int(length(data_dict["longitude"])/(num_years))
n_lat = Int(length(data_dict["latitude"])/(num_years))

temp_long = data_dict["longitude"][1:n_lon]
temp_lat = data_dict["latitude"][1:n_lat]

println("n_lon = $n_lon ")
println("n_lat = $n_lat ")

data_dict_temp = reshape(data_dict["t2m"], (n_lon,n_lat,num_days*24))
data_dict_time = data_dict["time"]

time_entries=[]
time_entries_all=[]
daily_temp = Array{Float64}(undef,n_lon,n_lat,1);

for i in 1:length(data_dict_time)
    a = data_dict_time[i]
    year = Dates.year(a)
    month = Dates.month(a)
    day = Dates.day(a)
    time_entry = Date(year,month,day)
    push!(time_entries,time_entry)
end

display(time_entries)
calender = Date.(time_entries[1]:Day(1):time_entries[end])
append!(time_entries_all,calender)
```

```{julia}

for date in calender
    indexArray = findall(x->x==date, time_entries)
    # display(indexArray) 
    hourly_temp = data_dict_temp[:,:,indexArray]
    average = mean(hourly_temp,dims=3)
    display(date)
    daily_temp = cat(daily_temp,average,dims =3)
    # daily_temp[:,:,j] = average[:,:,:]
    # j+=1
end

display(daily_temp)
```

```{julia} 
# ###Dont run this
# using CDSAPI
# using NCDatasets
# using StatsBase: shuffle

# base_path="data/raw"

# files = ["2m_temperature_1990.nc", "2m_temperature_1991.nc","2m_temperature_1992.nc",]#"2m_temperature_1993.nc","2m_temperature_1994.nc","2m_temperature_1995.nc","2m_temperature_1996.nc","2m_temperature_1997.nc","2m_temperature_1998.nc","2m_temperature_1999.nc","2m_temperature_2000.nc"],"2m_temperature_2001.nc","2m_temperature_2002.nc","2m_temperature_2003.nc","2m_temperature_2004.nc","2m_temperature_2005.nc","2m_temperature_2006.nc","2m_temperature_2007.nc","2m_temperature_2008.nc","2m_temperature_2009.nc","2m_temperature_2010.nc","2m_temperature_2011.nc","2m_temperature_2012.nc","2m_temperature_2013.nc","2m_temperature_2014.nc","2m_temperature_2015.nc","2m_temperature_2016.nc","2m_temperature_2017.nc","2m_temperature_2018.nc","2m_temperature_2019.nc","2m_temperature_2020.nc"]

# time_entries_all=[]
# temp_long = []
# temp_lat = []
# j=1
# daily_temp = Array{Float64}(undef,n_lon,n_lat,1);
# display(daily_temp)
# for file in files 
#     display(string(file))
#     file = joinpath(base_path, file)
#     ds=Dataset(file,"r")
#     temp_long = ds["longitude"][:]
#     temp_lat = ds["latitude"][:]
#     temp = ds["t2m"][:,:,:]
#     time = ds["time"][:]
#     time_entries_year = []
#     indexArray = []

#     #display(time)

#     for i in 1:length(time)
#         a = time[i]
#         year = Dates.year(a)
#         month = Dates.month(a)
#         day = Dates.day(a)
#         time_entry = Date(year,month,day)
#         push!(time_entries_year,time_entry)
        
#     end
#     display(time_entries_year)

#     calender = Date.(time_entries_year[1]:Day(1):time_entries_year[end])
#     #display(calender)
#     append!(time_entries_all,calender)
    

#     for date in calender
#         indexArray = findall(x->x==date, time_entries_year)
#         # display(indexArray) 
#         hourly_temp = temp[:,:,indexArray]
#         average = mean(hourly_temp,dims=3)
#         #display(average)
#         daily_temp = cat(daily_temp,average,dims =3)
#         # daily_temp[:,:,j] = average[:,:,:]
#         # j+=1
#     end




# end
# display(daily_temp)
# # display(time_entries)
# # display(temp_lat)
# # display(temp_long)
# # display(daily_temp)
```


```{julia}
daily_temp_data = copy(daily_temp[:,:,2:end])
display(daily_temp_data)
temp_lat=reverse(temp_lat)
daily_temp_reverse=reverse(daily_temp_data;dims=2)
```


```{julia}

display(temp_long)
display(temp_lat)
display(daily_temp_data[:,:,:])

heatmap(temp_long,temp_lat,transpose(daily_temp_reverse[:,:,20]),xlabel="Longitude",ylabel="Latitude",title="Temperature on $(time_entries_all[20])")


```



```{julia}
display(temp_long)
temp_long_1=copy(temp_long)

lon_min = -108
lon_max = -93
i, j = findall(x -> x in [lon_min, lon_max], temp_long_1)
display(i)
display(j)
# Subset the array to include longitudes within the specified range
temp_long_tx = temp_long_1[(temp_long_1 .>= lon_min) .& (temp_long_1 .<= lon_max)]

#display(temp_long_htx)


#display(temp_lat)
temp_lat_1=copy(temp_lat)

lat_min = 26
lat_max = 37
a,b = findall(x -> x in [lat_min, lat_max], temp_lat_1)
display(a)
display(b)
# Subset the array to include longitudes within the specified range
temp_lat_tx = temp_lat_1[(temp_lat_1 .>= lat_min) .& (temp_lat_1 .<= lat_max)]

#display(temp_lat_htx)


```



```{julia}
daily_temp_tx=[]
daily_temp_1= copy(daily_temp_reverse)
display(daily_temp_1)
display(time_entries)
daily_temp_tx = daily_temp_1[i:j,a:b,:]
day = 200
date = time_entries[day]
heatmap(temp_long_tx,temp_lat_tx,transpose(daily_temp_tx[:,:,day]),xlabel="Longitude",ylabel="Latitude",title="Temperature on $(date)")
```




```{julia}
# daily_temp_tx=[]
# daily_temp_1= copy(daily_temp_reverse)
# display(daily_temp_1)
# display(time_entries)
# # daily_temp_tx = daily_temp_1[i:j,a:b,:]
# daily_temp_tx = daily_temp_1[:,:,:]


# for day in  1:1000
#     print(day,"\n")
#     date = time_entries_all[day]
#     h = heatmap(temp_long,temp_lat,transpose(daily_temp_tx[:,:,day]),xlabel="Longitude",ylabel="Latitude",title="Temperature on $(date)",clims=(250.,315.))
#     display(h)
#     sleep(0.01)
# end

```



```{julia}


using CDSAPI
using NCDatasets
using StatsBase: shuffle
base_path="data/raw1"
files1 = ["2m_dewpoint_temperature_1990.nc", "2m_dewpoint_temperature_1991.nc", "2m_dewpoint_temperature_1992.nc","2m_dewpoint_temperature_1993.nc","2m_dewpoint_temperature_1994.nc","2m_dewpoint_temperature_1995.nc","2m_dewpoint_temperature_1996.nc","2m_dewpoint_temperature_1997.nc","2m_dewpoint_temperature_1998.nc","2m_dewpoint_temperature_1999.nc","2m_dewpoint_temperature_2000.nc","2m_dewpoint_temperature_2001.nc","2m_dewpoint_temperature_2002.nc","2m_dewpoint_temperature_2003.nc","2m_dewpoint_temperature_2004.nc","2m_dewpoint_temperature_2005.nc","2m_dewpoint_temperature_2006.nc","2m_dewpoint_temperature_2007.nc","2m_dewpoint_temperature_2008.nc","2m_dewpoint_temperature_2009.nc","2m_dewpoint_temperature_2010.nc","2m_dewpoint_temperature_2011.nc","2m_dewpoint_temperature_2012.nc","2m_dewpoint_temperature_2013.nc","2m_dewpoint_temperature_2014.nc","2m_dewpoint_temperature_2015.nc","2m_dewpoint_temperature_2016.nc","2m_dewpoint_temperature_2017.nc","2m_dewpoint_temperature_2018.nc","2m_dewpoint_temperature_2019.nc","2m_dewpoint_temperature_2020.nc"]
file_paths1 = [joinpath(base_path, file) for file in files1]
data_dict_1 = open_mfdataset(file_paths1, "d2m")
#Check for missing values in them
#Check spatial and temporal dimensions, if it matches with your y dimensions

```


```{julia}
start_date = Date(data_dict_1["time"][1])
end_date = Date(data_dict_1["time"][end])

println(start_date)
println(end_date)

# Calculate the number of days between the two dates
num_days = (end_date) - (start_date) 
num_days = Dates.value(num_days) + 1
num_years = (Dates.year(end_date) - Dates.year(start_date)) + 1

println("Number of days from $(Dates.year(start_date)) to $(Dates.year(end_date)): $num_days and $num_years years" )

n_lon = Int(length(data_dict_1["longitude"])/(num_years))
n_lat = Int(length(data_dict_1["latitude"])/(num_years))
println("n_lon = $n_lon ")
println("n_lat = $n_lat ")

data_dict_dewtemp = reshape(data_dict_1["d2m"], (n_lon,n_lat,num_days*24))
data_dict_time1 = data_dict_1["time"]
time_entries=[]
time_entries_all=[]
daily_dewtemp = Array{Float64}(undef,n_lon,n_lat,1);

for i in 1:length(data_dict_time1)
    a = data_dict_time1[i]
    year = Dates.year(a)
    month = Dates.month(a)
    day = Dates.day(a)
    time_entry = Date(year,month,day)
    push!(time_entries,time_entry)
end
display(time_entries)
calender = Date.(time_entries[1]:Day(1):time_entries[end])
append!(time_entries_all,calender)
for date in calender
    indexArray = findall(x->x==date, time_entries)
    # display(indexArray) 
    hourly_dewtemp = data_dict_dewtemp[:,:,indexArray]
    average1 = mean(hourly_dewtemp,dims=3)
    display(date)
    daily_dewtemp = cat(daily_dewtemp,average1,dims =3)
    # daily_dewtemp[:,:,j] = average[:,:,:]
    # j+=1
end

display(daily_dewtemp)
```

```{julia}
daily_dewtemp_data = copy(daily_dewtemp[:,:,2:end])
display(daily_dewtemp_data)
#temp_lat=reverse(temp_lat)
daily_dewtemp_reverse=reverse(daily_dewtemp_data;dims=2)
```

```{julia}

display(temp_long)
display(temp_lat)
display(daily_dewtemp_data[:,:,:])

heatmap(temp_long,temp_lat,transpose(daily_dewtemp_reverse[:,:,20]),xlabel="Longitude",ylabel="Latitude",title="Dewpoint Temperature on $(time_entries_all[20])")
```


```{julia}
display(temp_long)
temp_long_1=copy(temp_long)

lon_min = -108
lon_max = -93
i, j = findall(x -> x in [lon_min, lon_max], temp_long_1)
display(i)
display(j)
# Subset the array to include longitudes within the specified range
temp_long_tx = temp_long_1[(temp_long_1 .>= lon_min) .& (temp_long_1 .<= lon_max)]

#display(temp_long_htx)


#display(temp_lat)
temp_lat_1=copy(temp_lat)

lat_min = 26
lat_max = 37
a,b = findall(x -> x in [lat_min, lat_max], temp_lat_1)
display(a)
display(b)
# Subset the array to include longitudes within the specified range
temp_lat_tx = temp_lat_1[(temp_lat_1 .>= lat_min) .& (temp_lat_1 .<= lat_max)]

#display(temp_lat_htx)


```



```{julia}
daily_dewtemp_tx=[]
daily_dewtemp_1= copy(daily_dewtemp_reverse)
display(daily_temp_1)
display(time_entries)
daily_dewtemp_tx = daily_dewtemp_1[i:j,a:b,:]
day = 200
date = time_entries[day]
heatmap(temp_long_tx,temp_lat_tx,transpose(daily_dewtemp_tx[:,:,day]),xlabel="Longitude",ylabel="Latitude",title="Dew Point Temperature on $(date)")
```


# splitting data for training and testing
```{julia}
unique_years=unique(year.(time_entries_all))
num_years=length(unique_years)
split_year=unique_years[end-9]
split_index=findfirst(x->year(x)==split_year,time_entries_all)
precip_train=obprecip_subset[:,:,1:split_index]
precip_test= obprecip_subset[:,:,(split_index+1):end]
temp_train= daily_temp_tx[:,:,1:split_index]
temp_test=daily_temp_tx[:,:,(split_index+1):end]
dewtemp_train=daily_dewtemp_tx[:,:,1:split_index]
dewtemp_test=daily_dewtemp_tx[:,:,(split_index+1):end]
#display(idx_partition)
#train_index=[]
#train_idx = 1:idx_partition
#display(train_index)
#test_idx = (idx_partition+1):length(time)
#precip_train = obprecip_subset[:, :, train_idx]

```

# preprocessing
```{julia}
function preprocess(temp::Array{T,3},temp_ref::Array{T,3})::AbstractMatrix where {T}
n_lon,n_lat,n_t=size(temp)
display(n_lon)
mean_value=mean(temp_ref;dims=3)
std_dev=std(temp_ref;dims=3)
temp_anom=(temp.-mean_value)./std_dev
temp_anom=reshape(temp_anom,n_lon * n_lat,n_t)
return(temp_anom)
end
```



```{julia}
temp_mat_train=preprocess(temp_train,temp_train)
temp_mat_test=preprocess(temp_test,temp_train)
dewtemp_mat_train=preprocess(dewtemp_train,dewtemp_train)
dewtemp_mat_test=preprocess(dewtemp_test,dewtemp_train)
```


# Principal Component Analysis

```{julia}
# temp_train_transposed=
#X_train= hcat(temp_mat_train,dewtemp_mat_train)
#X_test= hcat(temp_mat_test, dewtemp_mat_test)
# X_train = cat(temp_mat_train, dewtemp_mat_train, dims=1)
```

```{julia}
pca_model_both=fit(PCA,X_train;maxoutdim=30,pratio=0.999)
display(principalvars(pca_model_both))
p2=plot(principalvars(pca_model_both)/var(pca_model_both);xlabel="# of PCs",ylabel="fraction of variance explained",label=false,title="Variance Explained")
```

```{julia}

println(size(temp_lat_tx))
println(size(temp_long_tx))
println(size(pc))


```


```{julia}

# p = []
# for i in 1:5
#     pc = projection(pca_model_both)[:, i]
#     pc = reshape(pc, length(temp_lat_tx),length(temp_long_tx))'
#     pi = heatmap(
#         temp_long_tx,  # Adjusted to match size of pc
#         temp_lat_tx,   # Adjusted to match size of pc
#         pc,
#         xlabel="Longitude",
#         ylabel="Latitude",
#         title="PC $i",
#         aspect_ratio=:equal,
#         cmap=:PuOr
#     )
#     push!(p, pi)
# end
# plot(p...; layout=(3, 2), size=(1500, 600))




```

```{julia}

p = []
for i in 1:5
    pc = projection(pca_model_both)[:, i]

    # Split into temperature and dewpoint parts
    pc_temp = pc[1:192]  # First half for temperature
    pc_dew = pc[193:end]  # Second half for dewpoint

    # Reshape each part
    pc_temp_reshaped = reshape(pc_temp, length(temp_lat_tx), length(temp_long_tx))'
    pc_dew_reshaped = reshape(pc_dew, length(temp_lat_tx), length(temp_long_tx))'

    # Create heatmaps for each part
    pi_temp = heatmap(
        temp_long_tx,
        temp_lat_tx,
        pc_temp_reshaped,
        xlabel="Longitude",
        ylabel="Latitude",
        title="Temp Component of PC $i",
        aspect_ratio=:equal,
        cmap=:PuOr
    )
    pi_dew = heatmap(
        temp_long_tx,
        temp_lat_tx,
        pc_dew_reshaped,
        xlabel="Longitude",
        ylabel="Latitude",
        title="Dewpoint Component of PC $i",
        aspect_ratio=:equal,
        cmap=:PuOr
    )

    push!(p, pi_temp)
    push!(p, pi_dew)
end
plot(p...; layout=(5, 4), size=(1500, 1200))


```



```{julia}

pc_ts = predict(pca_model_both, X_train)
day_of_year = Dates.dayofyear.(time)
p = []
for i in 1:5
pi = scatter(
            day_of_year,
            pc_ts[i, :];
            xlabel="Day of Year",
            ylabel="PC $i",
            title="PC $i",
            label=false,
            alpha=0.3,
            color=:gray
            )
push!(p, pi)
end
plot(p...; layout=(1, 5), size=(1500, 1000))


```





```{julia}

# pc_ts = predict(pca_model_both, temp_mat_train)
# day_of_year = Dates.dayofyear.(time)
# p = []
# for i in 1:5
# pi = scatter(
# day_of_year,
# pc_ts[i, :];
# xlabel="Day of Year",
# ylabel="PC $i",
# title="PC $i",
# label=true,
# alpha=0.3,
# color=:gray
# )
# push!(p, pi)
# end
# plot(p...; layout=(1, 5), size=(1500, 600))


```


```{julia}
function euclidian_distance(x::AbstractVector,y::AbstractVector)::AbstractFloat
return sqrt(sum((x .- y).^2))
end

function nsmallest(x::AbstractVector,n::Int)::Vector{Int}
  idx=sortperm(x)
  return idx[1:n]
end

function knn(X::AbstractMatrix,Xi::AbstractVector,K::Int)::Tuple{Int,AbstractVector}
dist=[euclidian_distance(Xi,X[j,:]) for j in 1:size(X,1)]
idx=nsmallest(dist,K)
w= 1 ./dist[idx]
w./=sum(w)
#idx_sample = sample(idx,Weights(w))
idx_sample = sample(idx, Weights(w))
return (idx_sample,vec(X[idx_sample,:]))
end
```

```{julia}
# let 
# X = collect([-1 0 1 2 3 4 5 6 7 8 9 10]')
# Xi=[5.4]
# K=3
# samples=[]

# for i in 1:1000
# idx,X_sample=knn(X,Xi,K)
# push!(samples,X_sample[1])
# end
# histogram(samples;bins=vec(X).+0.5,label="Samples",normalize=:pdf,xticks=vec(X))
# dist=[0.4,0.6,1.4]
# w=1 ./dist
# w./=sum(w)
# scatter!([5, 6, 4],w;label="Analytical",markersize=7)
# end

```


```{julia}
function predict_knn_combined(temp_train,temp_test,dewtemp_train,dewtemp_test,precip_train;n_pca::Int)

temp_mat_train=preprocess(temp_train,temp_train)
temp_mat_test=preprocess(temp_test,temp_train)
dewtemp_mat_train=preprocess(dewtemp_train,dewtemp_train)
dewtemp_mat_test=preprocess(dewtemp_test,dewtemp_train)

#X_train= hcat(temp_mat_train,dewtemp_mat_train)
#X_test= hcat(temp_mat_test, dewtemp_mat_test)

X_train = cat(temp_mat_train, dewtemp_mat_train, dims=1)
X_test = cat(temp_mat_test, dewtemp_mat_test, dims=1)

pca_model= fit(PCA,X_train;maxoutdim=n_pca)

train_embedded = predict(pca_model,X_train)
test_embedded = predict(pca_model,X_test)


println("Dimensions of train_projected: $(size(train_projected))")


precip_predict = map(1:size(X_test,2)) do i
idx,_=knn(train_embedded',test_embedded[:,i],2)

display(idx)
precip_train[:,:,idx]
end

return precip_predict
end

```

```{julia}
pca_model=fit(PCA,X_train;maxoutdim=5)
train_projected=predict(pca_model,X_train)
test_projected=predict(pca_model,X_test)

precip_pred_combined=map(1:size(X_test,2)) do i
idx,_=knn(train_projected',test_projected[:,1],3)
display(idx)
precip_train[:,:,idx]
end
```
```{julia}
display(train_projected)
```

```{julia}
t_sample_combined1 = rand(1:size(temp_test, 3), 3)
precip_pred_combined1 = predict_knn_combined(temp_train, temp_test[:, :, t_sample_combined], dewtemp_train, dewtemp_test[:, :, t_sample_combined], precip_train; n_pca=10)
display(precip_pred_combined1)

```

```{julia}
t_sample = rand(1:size(X_train, 3),3)
p = map(eachindex(t_sample)) do ti
t = t_sample[ti]
display(t_sample)
y_pred = precip_pred_combined[ti]'
y_actual = precip_test[:, :, t]'
cmax = max(maximum(skipmissing(y_pred)), maximum(skipmissing(y_actual)))

p1 = heatmap(
obprecip_lon,
obprecip_lat,
y_pred;
xlabel="Longitude",
ylabel="Latitude",
title="Predicted",
aspect_ratio=:equal,
clims=(0, cmax)
)
p2 = heatmap(
obprecip_lon,
obprecip_lat,
y_actual;
xlabel="Longitude",
ylabel="Latitude",
title="Actual",
aspect_ratio=:equal,
clims=(0, cmax)
)
plot(p1, p2; layout=(2, 1), size=(1000, 400))
end
plot(p...; layout=(2, 3), size=(1500, 1200))
```






# Trying the knn model separately for dewpoint T and air T
```{julia}
# function predict_knn(temp_train, temp_test, precip_train; n_pca::Int)
# X_train1 = preprocess(temp_train, temp_train)
# X_test1 = preprocess(temp_test, temp_train)
# # fit the PCA model to the training data
# pca_model = fit(PCA, X_train; maxoutdim=n_pca)
# # project the test data onto the PCA basis
# train_embedded = predict(pca_model, X_train1)
# test_embedded = predict(pca_model, X_test1)
# display(train_embedded)
# # use the `knn` function for each point in the test data
# precip_pred = map(1:size(X_test1, 2)) do i
# idx, _ = knn(train_embedded', test_embedded[:, i], 3)
# display(idx)
# precip_train[:, :, idx]
# end
# return precip_pred
# end
```

# visualizing for air temp
```{julia}

# t_sample = rand(1:size(temp_test, 3), 3)
# precip_pred = predict_knn(temp_train, temp_test[:, :, t_sample], precip_train; n_pca=3)

# p = map(eachindex(t_sample)) do ti
# t = t_sample[ti]
# display(t_sample)
# y_pred = precip_pred[ti]'
# y_actual = precip_test[:, :, t]'
# cmax = max(maximum(skipmissing(y_pred)), maximum(skipmissing(y_actual)))

# p1 = heatmap(
# obprecip_lon,
# obprecip_lat,
# y_pred;
# xlabel="Longitude",
# ylabel="Latitude",
# title="Predicted",
# aspect_ratio=:equal,
# clims=(0, cmax)
# )
# p2 = heatmap(
# obprecip_lon,
# obprecip_lat,
# y_actual;
# xlabel="Longitude",
# ylabel="Latitude",
# title="Actual",
# aspect_ratio=:equal,
# clims=(0, cmax)
# )
# plot(p1, p2; layout=(2, 1), size=(1000, 400))
# end
# plot(p...; layout=(2, 3), size=(1500, 1200))


```

# For dewpoint T
```{julia}
# t_sample = rand(1:size(dewtemp_test, 3), 3)
# precip_pred = predict_knn(dewtemp_train, dewtemp_test[:, :, t_sample], precip_train; n_pca=3)
```

# Calculating mse 
```{julia}
using Statistics
mse = mean([mean(skipmissing((precip_pred_combined1[i] .- precip_test[:, :, i]).^2)) for i in 1:length(precip_pred_combined1)])



#mse = mean([mean((precip_pred_combined1[i] .- precip_test[:, :, i]).^2) for i in 1:length(precip_pred_combined1)])

#mse = mean((precip_pred_combined1 .- precip_test).^2)

# #mse = mean((precip_predicted.- precip_test).^2)
# #mae = mean(abs.(precip_pred .- precip_actual))
# #mse = mean((precip_predicted .- mean(precip_test)).^2)


# println("Mean Squared Error: $mse")
# println("Mean Absolute Error: $mae")

```

```{julia}
# Assuming precip_train is a 3D array (lon, lat, time)
n_time_points = size(precip_train, 3)
mean_precip = sum([mean(skipmissing(precip_train[:, :, t])) for t in 1:n_time_points]) / n_time_points

# Repeat the mean value across the spatial dimensions and time points
precip_pred_baseline = repeat(reshape([mean_precip], 1, 1), size(precip_test, 1), size(precip_test, 2), size(precip_test, 3))

# Calculating MSE, ensuring to handle missing values
mse_baseline = mean(skipmissing((precip_pred_baseline .- precip_test).^2))


```